{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for number of lines of the form CAPS PUNCT NormalCase\n",
    "# if there are few/none, the play is probably of the form \"NAME\\nLine\"\n",
    "def exploratory_sectioning(script):\n",
    "    # lines = script.split('\\n')\n",
    "    # typical_speech_lines = [line for line in lines if speech_regex.match(line)]\n",
    "    # print(len(typical_speech_lines) / len(lines))\n",
    "    # if len(typical_speech_lines) < len(lines)/4:\n",
    "    #     line_bigrams = [(lines[i], lines[i+1]) for i in range(len(lines) - 1)]\n",
    "    #     contentful_bigrams = [bigram for bigram in line_bigrams if bigram[0] and bigram[1]]\n",
    "    #     twoline_lines = [bigram for bigram in contentful_bigrams if caps_regex.match(bigram[0]) and prose_regex.match(bigram[1])]\n",
    "    #     print(len(twoline_lines) / len(contentful_bigrams))\n",
    "    from src.clean_scripts import consolidate_lines, determine_mode\n",
    "    mode = determine_mode(script)\n",
    "    lines = consolidate_lines(script, mode)\n",
    "    sectionize_play('\\n'.join(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect context surrounding \"enter\", \"exit\"; probably indicative of general stage directions\n",
    "def stage_directions(text):\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    enter_exit_context = defaultdict(lambda: 0)\n",
    "    for line in lines:\n",
    "        tokens = line.split()\n",
    "        for token in tokens:\n",
    "            if 'enter' in token.lower() or 'exit' in token.lower():\n",
    "                to_add = token.lower().replace('enter', '<TEXT>').replace('exit', '<TEXT>')\n",
    "                if len(to_add.replace('<TEXT>', '')) == 0:\n",
    "                    continue \n",
    "                if len([c for c in to_add.replace('<TEXT>', '') if c.isalpha()]) > 0:\n",
    "                    # if there are other letters in the string, ignore\n",
    "                    continue\n",
    "                enter_exit_context[to_add] += 1\n",
    "    scene_punct = sorted(enter_exit_context.items(), key=lambda x:x[1], reverse=True)\n",
    "    if sum([x[1] for x in scene_punct]) >= len(lines) * 0.05:\n",
    "        print(scene_punct)\n",
    "    # if line starts with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('_<TEXT>_', 56), ('[_<TEXT>_.', 35), ('[_<TEXT>_', 20), ('[_<TEXT>', 7), ('_<TEXT>', 6), ('<TEXT>_.', 5), ('<TEXT>_', 2), ('[_<TEXT>,', 2), ('[<TEXT>_', 1), ('<TEXT>.', 1), ('[<TEXT>.', 1), ('[_<TEXT>.', 1)]\n",
      "[('<TEXT>.', 1)]\n",
      "[('[<TEXT>', 69), ('[<TEXT>.]', 45), ('[<TEXT>.', 3), ('<TEXT>.]', 2), ('<TEXT>,', 1), ('<TEXT>;', 1), ('[<TEXT>,', 1), ('<TEXT>.', 1)]\n",
      "[('[<TEXT>', 1)]\n",
      "[('[<TEXT>', 11), ('[<TEXT>]', 2), ('[<TEXT>.]', 2), ('[<TEXT>:', 1), ('<TEXT>.]', 1)]\n",
      "[('[_<TEXT>', 2)]\n",
      "[('[_<TEXT>_', 32), ('[_<TEXT>', 3), ('_<TEXT>_', 2), ('<TEXT>_.]', 1), ('[_<TEXT>_.]', 1), ('[_<TEXT>_]', 1)]\n",
      "[('[_<TEXT>_', 31), ('[_<TEXT>', 11), ('_<TEXT>_', 4), ('[_<TEXT>_.]', 2), ('[<TEXT>', 1)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    in_dir = '../final_project/play_scripts'\n",
    "    for fname in os.listdir(in_dir):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(in_dir, fname), 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            stage_directions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_<TEXT>_',\n",
       " '[_<TEXT>_.',\n",
       " '[_<TEXT>_',\n",
       " '[_<TEXT>',\n",
       " '_<TEXT>',\n",
       " '<TEXT>_.',\n",
       " '<TEXT>_',\n",
       " '[<TEXT>_',\n",
       " '<TEXT>.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def consolidate_regex_rules(rules):\n",
    "    simplest_rules = [rules[0]]\n",
    "    for new_rule in rules[1:]:\n",
    "        move_on = False\n",
    "        for simple_rule in simplest_rules:\n",
    "            if not move_on:\n",
    "                if simple_rule in new_rule:\n",
    "                    if simple_rule not in ['_<TEXT>', '<TEXT>_', '_<TEXT>_', '(<TEXT>)', '[<TEXT>]']:\n",
    "                        move_on = True  # new rule is contained in an existing nontrivial rule\n",
    "                # elif new_rule in simple_rule and new_rule not in ['_<TEXT>', '<TEXT>_', '_<TEXT>_', '(<TEXT>)', '[<TEXT>]']:\n",
    "                #     simplest_rules.remove(simple_rule)\n",
    "                #     simplest_rules.append(new_rule)\n",
    "                #     move_on = True\n",
    "                # else:\n",
    "                #     simplest_rules.append(new_rule)\n",
    "                #     move_on = True\n",
    "        if not move_on:\n",
    "            if new_rule not in ['_<TEXT>', '<TEXT>_', '_<TEXT>_', '(<TEXT>)', '[<TEXT>]']:\n",
    "                for simple_rule in simplest_rules:\n",
    "                    if simple_rule not in ['_<TEXT>', '<TEXT>_', '_<TEXT>_', '(<TEXT>)', '[<TEXT>]']:\n",
    "                        if simple_rule in new_rule:\n",
    "                            simplest_rules.remove(simple_rule)\n",
    "            simplest_rules.append(new_rule)\n",
    "    return simplest_rules\n",
    "rules = [rule for rule, count in [('_<TEXT>_', 56), ('[_<TEXT>_.', 35), ('[_<TEXT>_', 20), ('[_<TEXT>', 7), ('_<TEXT>', 6), ('<TEXT>_.', 5), ('<TEXT>_', 2), ('[_<TEXT>,', 2), ('[<TEXT>_', 1), ('<TEXT>.', 1), ('[<TEXT>.', 1), ('[_<TEXT>.', 1)]]\n",
    "consolidate_regex_rules(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[_<TEXT>',\n",
       " '_<TEXT>',\n",
       " '<TEXT>_.',\n",
       " '<TEXT>_',\n",
       " '<TEXT>_',\n",
       " '<TEXT>_',\n",
       " '[_<TEXT>,',\n",
       " '[_<TEXT>,',\n",
       " '[_<TEXT>,',\n",
       " '[_<TEXT>,',\n",
       " '[<TEXT>_',\n",
       " '[<TEXT>_',\n",
       " '[<TEXT>_',\n",
       " '[<TEXT>_',\n",
       " '[<TEXT>_',\n",
       " '[<TEXT>_',\n",
       " '[<TEXT>_',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.',\n",
       " '[_<TEXT>.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = [rule for rule, count in [('_<TEXT>_', 56), ('[_<TEXT>_.', 35), ('[_<TEXT>_', 20), ('[_<TEXT>', 7), ('_<TEXT>', 6), ('<TEXT>_.', 5), ('<TEXT>_', 2), ('[_<TEXT>,', 2), ('[<TEXT>_', 1), ('<TEXT>.', 1), ('[<TEXT>.', 1), ('[_<TEXT>.', 1)]]\n",
    "consolidate_regex_rules(rules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
